{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050731c9-99db-46b8-8645-2c7333097540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T16:53:56.965065Z",
     "iopub.status.busy": "2021-04-27T16:53:56.964891Z",
     "iopub.status.idle": "2021-04-27T16:53:56.967236Z",
     "shell.execute_reply": "2021-04-27T16:53:56.966719Z",
     "shell.execute_reply.started": "2021-04-27T16:53:56.965029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Animal classification\n",
    "# https://www.kaggle.com/stpeteishii/animal-detection-by-yolo-coco-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dd44334-f2dc-4db1-ab96-09defd28b711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T18:14:00.307034Z",
     "iopub.status.busy": "2021-04-27T18:14:00.306898Z",
     "iopub.status.idle": "2021-04-27T18:14:00.309563Z",
     "shell.execute_reply": "2021-04-27T18:14:00.309095Z",
     "shell.execute_reply.started": "2021-04-27T18:14:00.307019Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11737b4c-8596-4cd5-b66c-85719a0353d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T18:18:47.811055Z",
     "iopub.status.busy": "2021-04-27T18:18:47.810933Z",
     "iopub.status.idle": "2021-04-27T18:18:47.987932Z",
     "shell.execute_reply": "2021-04-27T18:18:47.987518Z",
     "shell.execute_reply.started": "2021-04-27T18:18:47.811042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example of loading the mnist dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad14229a-a083-434f-b716-516fe1db520b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T18:19:08.926108Z",
     "iopub.status.busy": "2021-04-27T18:19:08.925932Z",
     "iopub.status.idle": "2021-04-27T18:19:09.304544Z",
     "shell.execute_reply": "2021-04-27T18:19:09.304045Z",
     "shell.execute_reply.started": "2021-04-27T18:19:08.926080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "BATCH_SIZE = 64\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = (\n",
    "    train_ds.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "181b9400-87f8-4e37-b5e1-b8f41c2f9904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T18:19:11.009031Z",
     "iopub.status.busy": "2021-04-27T18:19:11.008392Z",
     "iopub.status.idle": "2021-04-27T18:19:11.109220Z",
     "shell.execute_reply": "2021-04-27T18:19:11.108809Z",
     "shell.execute_reply.started": "2021-04-27T18:19:11.008957Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate all the dataset, and retrieve only the y\n",
    "# Then filter only for unique\n",
    "class_names = list(set(np.concatenate([y for x, y in train_ds], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a39527a-b79c-420c-ab9f-5e7efc11ed2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T18:19:12.180696Z",
     "iopub.status.busy": "2021-04-27T18:19:12.180349Z",
     "iopub.status.idle": "2021-04-27T18:19:12.212375Z",
     "shell.execute_reply": "2021-04-27T18:19:12.211917Z",
     "shell.execute_reply.started": "2021-04-27T18:19:12.180655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: tf.Tensor(\n",
      "[1 1 6 3 5 1 7 3 0 4 7 4 6 0 1 1 4 5 9 5 7 4 9 1 8 1 6 9 2 8 8 7 9 6 2 5 0\n",
      " 4 5 6 6 4 1 1 1 4 9 9 7 0 6 2 4 3 9 8 1 8 0 7 0 2 4 4], shape=(64,), dtype=uint8)\n",
      "Image shape: (64, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "for element in train_ds.take(1):\n",
    "    data = element[0]\n",
    "    labels = element[1]\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Image shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "740a38af-72e2-4d4b-af16-10b1a1509da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T18:20:52.684728Z",
     "iopub.status.busy": "2021-04-27T18:20:52.684562Z",
     "iopub.status.idle": "2021-04-27T18:20:52.727325Z",
     "shell.execute_reply": "2021-04-27T18:20:52.726912Z",
     "shell.execute_reply.started": "2021-04-27T18:20:52.684714Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.Rescaling(\n",
    "            1.0 / 255, input_shape=(img_height, img_width, 1)\n",
    "        ),\n",
    "        #         layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        #         layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(len(class_names), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d17f5a-8e83-4433-ae40-b6b2d8b03cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=10, batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a60de4b3-cf24-4e74-a8d3-33b6c09d10f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T17:26:27.226615Z",
     "iopub.status.busy": "2021-04-27T17:26:27.226271Z",
     "iopub.status.idle": "2021-04-27T17:26:27.953148Z",
     "shell.execute_reply": "2021-04-27T17:26:27.951272Z",
     "shell.execute_reply.started": "2021-04-27T17:26:27.226575Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9854\n",
      "Accuracy 0.9854000210762024\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(val_ds)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9b781fc-c7e0-4a4f-9b1f-693b2f7842e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T17:26:30.776277Z",
     "iopub.status.busy": "2021-04-27T17:26:30.775653Z",
     "iopub.status.idle": "2021-04-27T17:26:31.155399Z",
     "shell.execute_reply": "2021-04-27T17:26:31.155014Z",
     "shell.execute_reply.started": "2021-04-27T17:26:30.776203Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEuCAYAAABYs317AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPHElEQVR4nO3cf5RXdZ3H8debGRgVFJRfHXVgQn654rEfilK6cY6y1uknFrlbW7atu9mPcwzXtl2O5sm0lAC12C1rKyo0s05munoKamlTYBE9SXEABxXEcNIJhl+KCHz2j/th9zrNcN/DzLy/wDwf59xzvjP3/f3cz71zv6/v514+XEspCQAi9at1BwD0PQQPgHAED4BwBA+AcAQPgHAED4BwBE8fYGYfMbOHeqitJjPb0BNtHcK2X7UfZrbTzMYEbHeJmV3e29vpSwieDpjZBjN7KZ/YB5b5NexPTU58M7vMzFJXtm1mC8xsTz5mW8xskZlN7I3+pZQGpZSequhPU96H+t7oQyfbHGNm95vZDjNrNbPZUds+UhA8nXtnPrEPLJ+qdYcimdmJkv5V0upDePvslNIgSadKel7Sgg7aNzM76s4/MxsgaZGkX0l6jYpjsLCmnToMHXV/+N5mZl8zsx+Xfr7ZzH6ZP0hTzexZM5uVv+k2mNkHS7UNZjbHzJ4xsz+a2dfN7NjS+neb2W/NbLuZPWlmbzWzGyVdIGl+eeRlZhPzaGKLma0zs/eX2hlqZj/L7ayQdNoh7OqXJH1FUushvFeSlFJ6UdKdkiblfi0xsxvN7GFJL0oa0539yCOZsfn1sWY218w2mtk2M3soH9v/zuVt+fhNyfUfNbM1ZrbVzH5uZqNL7U4zs7W5nfmSrAu7/RFJm1NK81JKu1JKu1NKq7p46I5+KSWWdoukDZIu6mTdcZKeUHGCXaDig3lqXjdV0l5J8yQ1SHqLpF2SJuT1t0r6maSTJB0v6T5JX8rrJkvaJmmaii+EUyRNzOuWSLq81IeBkjZJ+jtJ9ZLekPtxRl5/l6S7c90kSX+Q9FDp/fdL+peD7P9kSStzP9pvu0nShoO8d4GkG/LrQSqC5zel/XhG0hm534O7uR9J0tj8+t9y+6dIqpP0pvw3aMp19aX3vUfSekmn5+1eI2lpXjdM0nZJ75PUX9LM/De9PK8fJalN0qhO9v/bkr4v6cG8L0sknVnrc/pwW2regcNxURE8O/MJdmD5h9L6yZK2SNoo6W9Kv5+aT9KBpd/dLelaFd+auySdVlo3RdLT+fXtkm7ppD/tP/yXHvgwl353u6Tr8ofuFeXQyuu+WP7AVux7nYrQmdLJtptUHTy78zFrURG0p5Xaur6n9iMHylgVAfmSpLM66E9HwfOgpL8v/dxPxQhstKQPS1peWmeSni0fg4rj94vc77dJGiDpM5KekjSg1uf14bSE3XA7Ar0npbS4oxUppRVm9pSkESqCpWxrSmlX6eeNkk6WNFzFaOlRs/8buZuKD5gkNUp6wNm30ZLONbO20u/qVXzTDs+vN7Xrg9cnJK1KKS3rwnvam5NSuqaTdeV+9dR+DJN0jKQnnf0bLek2M5tb+p2pGC2dXN5mSimZ2Sb5vaQiHB+UJDObo2JEdbqkx7vQzlGNezyHwMw+qWIYv1nSP7dbfaKZDSz9PCrXtao4Kc9IKQ3Jy+BU3ISVipO9s3sx7R8hsEnSr0vtDEnFDfCPS3pBxairsV0fvC6UNN3MWsysRcUly9we/Fe98r701H60qhhldXT8Onr8wiZJH2u33WNTSkslPVfephXfEo0dtNGZVZ1sE2W1HnIdjosOfo9nvKStks6SNC6/fl1eN1XFh2WOimH2BSourw7cq7lNxQhpRP75FEkX59eTVVyeXKg/v8dzl6QvlvpwvIpv/w+puA/RX9I5kk7P63+Y33OcpL9QcangvdQaouJfYw4sSyVdJWlwXt8k5z2eDtYt0asv27q1H/rzezy/VDFiqVNxGduQ37tP0vjS+6ZL+r3+/17SYEkz8uthknZIukTFiOtKle7xOI7fBBWXbRflfsxUMRLjUqu0MOLp3H3t5vHck+eCLJR0c0rp8ZRSs6RZkr5vZg35fS0qwmizpDskXZFSWpvXfVbFTc3lZrZd0mIVJ6pSSitU3GS9RcVN5l+ruCSQisB6X/4XmK+klHZI+itJf5230yLpZhUfNEn6lIobuy0qguA75R0zswfNbFZHO51SaksptRxYJO2RtD2ltK3LR7BCd/ejnasl/U7SIyruv90sqV8q/mXtRkkPm1mbmZ2XUronr78r/x1+r+KejFJKrZJmSLpJ0p9UfLk8fGAjZjYqnw8djr5SSusk/a2kr6s4D94t6V0ppT3+I3P0s5zS6AFmNlXSwpTSqTXuSq8xsyZJS1JKTTXuCo5gjHgAhCN40FVtKuYjAYeMSy0A4RjxAAhH8AAId9CZy9P6zeA6DMAhWbT/R53+51pGPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMLV17oDQF9j9dUfu93TXu9qa+v4/t3tzqu85ralPdpeZxjxAAhH8AAIR/AACEfwAAhH8AAIR/AACEfwAAhH8AAIR/AACMfMZaCH1A0Z7KpbM2dcZc36t93uamv5y64yTW5Irrp33PZGX4PdxIgHQDiCB0A4ggdAOIIHQDiCB0A4ggdAOIIHQDiCB0A4ggdAOGYuAxVefvs5rrrzb1zuqrtv+Dcqa8bee4WrrQnf2uWqe+LKBlfdOD3mqusuRjwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIxgRB92rOz3lRZc//HZrvaGtLP9z0+/odXVdZMvGaVq63mz5/lqjv9us2uur2uqu5jxAMgHMEDIBzBAyAcwQMgHMEDIBzBAyAcwQMgHMEDIBzBAyAcM5f7mJHLTqisadtznKutl9/S0t3u9Jrmr57rq7tkfmXNb3ZXHzNJmn6r73GlY7+6tLJmz4VvdLU17PHkqtv79EZXXRRGPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIxc/ko8fy9E111D4y6s7Jm7Ssvu9q6SlNcdT3JOyN53SX/7qpbsntAZc1nb/pHV1sjv1k9I9mrbWx1vyRp2DdX9Ng2IzHiARCO4AEQjuABEI7gARCO4AEQjuABEI7gARCO4AEQjuABEI6Zy7Vi5ip7/qcTXHUrz66ekSxJO1P1rOQZ//FPrrYa5ZupWzdsaGXNmtmvdbW1/uKvueoWveR7bvRNV364smbofy5zteW19bLqGd/Dv/WIq620f193u1MTjHgAhCN4AIQjeACEI3gAhCN4AIQjeACEI3gAhCN4AIRjAmEv6DdwYGVNy52Nrra8EwNnPud7JOgT56XKmsa9zomBQwa76nbecUJlzfpJ33C1dd0LZ7nqHrvUN/GyYZ1vol5POvG71RMSq/9KRzZGPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIxc7kLrN53uBoeGFRZs3Ksb0byHTtGuOrWXzbGVZf2rqsu6lfnamvt9RNddc2Tqh9XekPrJFdbj71/vKtu3xPrXXWeR9DunOGbFT7o7uW+bYIRD4B4BA+AcAQPgHAED4BwBA+AcAQPgHAED4BwBA+AcAQPgHDMXO6CJ7/nm13bPG5BZc11L5zpamvFh3x1+1evddV5Zuo233q2q6nm91bPSJakOVuqn3+8YrpzRvJTT7rq6oae5Kpbe/24ypqhj1YfM3QNIx4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOGYQCipbvxprrr/On++q27B9urHkK58x2tdbe3f5JsYWDfS94jUtddWb7d5um9i4E93DXHV/XjeRZU1x4/Z42rr6WuHuuqGj9juqmu6ZW9lTf/Fj7ragh8jHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOGYuSzJduxy1W3Z7ztcTf1bK2vWfGGkq626lkZXnY1+0VW35i89s6/rXG2dc8xmV93iL8yrrGndt8/V1kWLP+2qG/bRba66fX9sdtWhZzHiARCO4AEQjuABEI7gARCO4AEQjuABEI7gARCO4AEQjuABEM5SSp2unNZvRucrjyLWf4Cr7pkfjHfV/W7K97rTnV61X9V/0reume5qa/vuY1x16d7q5ySP+Mk6V1v7/rTFVYfaW7T/R9bZOkY8AMIRPADCETwAwhE8AMIRPADCETwAwhE8AMIRPADCETwAwvHMZUnplT2uusYZq111b68/r7Jmwx0TXG2tfvN3XXU3tE5y1f3PB86srKlf7ZtFfJKrysf3xGUcLRjxAAhH8AAIR/AACEfwAAhH8AAIR/AACEfwAAhH8AAIxwTCrjjIY2LL6k4eWVlz6YTHXG3NfO5cV92qz73OVdew+hFXHdCbGPEACEfwAAhH8AAIR/AACEfwAAhH8AAIR/AACEfwAAhH8AAIx8zlLrD+A1x1G285obJm9uCVrrYunzXTVXfCA8tddcDhgBEPgHAED4BwBA+AcAQPgHAED4BwBA+AcAQPgHAED4BwBA+AcMxc7oJNV5/tqlt17vzKmsmfv8rV1rA7l7nqgCMJIx4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOGYQChpz8W+iYH3XPFlV93r532msuaUhb91tbXfVQUcWRjxAAhH8AAIR/AACEfwAAhH8AAIR/AACEfwAAhH8AAIR/AACMfMZUnvnPsrX93Cq111TXOXVtYwIxl9GSMeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4Zi5LGnx+Y2uuqa2Zb3cE6BvYMQDIBzBAyAcwQMgHMEDIBzBAyAcwQMgHMEDIBzBAyAcwQMgHDOXJe1r21brLgB9CiMeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4QgeAOEIHgDhCB4A4SylVOs+AOhjGPEACEfwAAhH8AAIR/AACEfwAAhH8AAI97//pcW2aTLBjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for images, labels in train_ds.take(10):\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    pred_prob = [(np.argmax(p), max(p)) for p in model.predict(images)]\n",
    "    predictions = [class_names[a[0]] for a in pred_prob]\n",
    "    expected = [class_names[a] for a in labels]\n",
    "    not_match = [i for i in range(len(predictions)) if predictions[i] != expected[i]]\n",
    "    rows = columns = int(math.ceil(len(not_match)))\n",
    "    for i in range(len(not_match)):\n",
    "        fig.add_subplot(rows, columns, i + 1)\n",
    "        plt.imshow(images[not_match[i]].numpy().astype(\"uint8\"))\n",
    "        plt.title(\n",
    "            \"Expected: {}| Predicted: {}\".format(\n",
    "                expected[not_match[i]], predictions[not_match[i]]\n",
    "            )\n",
    "        )\n",
    "        plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
