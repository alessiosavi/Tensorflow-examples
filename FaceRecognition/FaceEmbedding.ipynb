{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192a2ffc-73f8-48f7-bccd-1676ddc5d88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T11:34:44.177134Z",
     "iopub.status.busy": "2021-04-28T11:34:44.176551Z",
     "iopub.status.idle": "2021-04-28T11:34:45.240639Z",
     "shell.execute_reply": "2021-04-28T11:34:45.240008Z",
     "shell.execute_reply.started": "2021-04-28T11:34:44.177061Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7e63fd-f46c-43e9-9cc7-af087f50c407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T11:34:45.241397Z",
     "iopub.status.busy": "2021-04-28T11:34:45.241293Z",
     "iopub.status.idle": "2021-04-28T11:34:45.257024Z",
     "shell.execute_reply": "2021-04-28T11:34:45.256529Z",
     "shell.execute_reply.started": "2021-04-28T11:34:45.241384Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\n",
    "    \"/opt/SP/software/opencv/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4551e9d1-9e48-4ad5-8f00-0c7c89f55ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T11:34:45.257785Z",
     "iopub.status.busy": "2021-04-28T11:34:45.257682Z",
     "iopub.status.idle": "2021-04-28T11:34:45.287916Z",
     "shell.execute_reply": "2021-04-28T11:34:45.287514Z",
     "shell.execute_reply.started": "2021-04-28T11:34:45.257772Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector...\n",
      "[INFO] loading face recognizer...\n"
     ]
    }
   ],
   "source": [
    "# load our serialized face detector from disk\n",
    "print(\"[INFO] loading face detector...\")\n",
    "protoPath = \"dnn_models/deploy.prototxt\"\n",
    "modelPath = \"dnn_models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "detector.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "detector.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "# load our serialized face embedding model from disk\n",
    "print(\"[INFO] loading face recognizer...\")\n",
    "embedder = cv2.dnn.readNetFromTorch(\"dnn_models/openface.nn4.small2.v1.t7\")\n",
    "embedder.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "embedder.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8703f031-2cdf-4605-9433-bf9ebe9d57f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T11:51:03.872314Z",
     "iopub.status.busy": "2021-04-28T11:51:03.872182Z",
     "iopub.status.idle": "2021-04-28T11:51:03.930143Z",
     "shell.execute_reply": "2021-04-28T11:51:03.929767Z",
     "shell.execute_reply.started": "2021-04-28T11:51:03.872300Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_single_face(img_path: str) -> List[np.ndarray]:\n",
    "    faces = []\n",
    "    # Read the image\n",
    "    a = cv2.imread(img_path)\n",
    "    # Change color\n",
    "    gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "    # box_points: position (x,y,w,h) of the faces\n",
    "    # confidence: robustness of the prediction\n",
    "    box_points, _, confidence = face_cascade.detectMultiScale3(\n",
    "        gray, minNeighbors=50, outputRejectLevels=True\n",
    "    )\n",
    "    for i in range(len(confidence)):\n",
    "        # Filter for robust predictin\n",
    "        if confidence[i] > 2:\n",
    "            x, y, w, h = (\n",
    "                box_points[i][0],\n",
    "                box_points[i][1],\n",
    "                box_points[i][2],\n",
    "                box_points[i][3],\n",
    "            )\n",
    "            # Only save the face, anything else\n",
    "            crop_img = a[y : y + h, x : x + w]\n",
    "            faces.append(crop_img)\n",
    "    return faces\n",
    "\n",
    "\n",
    "x = filter_single_face(\"/home/alessiosavi/Downloads/a.jpg\")\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fd86c10-2ff3-4ab4-9bb3-8e1ae0624e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T12:09:39.620098Z",
     "iopub.status.busy": "2021-04-28T12:09:39.619651Z",
     "iopub.status.idle": "2021-04-28T12:09:39.657658Z",
     "shell.execute_reply": "2021-04-28T12:09:39.657280Z",
     "shell.execute_reply.started": "2021-04-28T12:09:39.620044Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPENCV DNN\n",
    "def filter_single_face_dnn(img_path: str) -> List[np.ndarray]:\n",
    "    faces = []\n",
    "    img = cv2.imread(img_path)\n",
    "    height, width = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 117.0, 123.0)\n",
    "    )\n",
    "    detector.setInput(blob)\n",
    "    faces3 = detector.forward()\n",
    "    for i in range(faces3.shape[2]):\n",
    "        confidence = faces3[0, 0, i, 2]\n",
    "        if confidence > 0.9:\n",
    "            box = faces3[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            crop_img = img[y:y1, x:x1]\n",
    "            faces.append(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB))\n",
    "    return faces\n",
    "\n",
    "\n",
    "x = filter_single_face_dnn(\"/home/alessiosavi/Downloads/a.jpg\")\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da758cdc-06db-4dae-905d-972008fdd4e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T11:54:05.000014Z",
     "iopub.status.busy": "2021-04-28T11:54:04.999369Z",
     "iopub.status.idle": "2021-04-28T11:54:05.004529Z",
     "shell.execute_reply": "2021-04-28T11:54:05.004151Z",
     "shell.execute_reply.started": "2021-04-28T11:54:04.999939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "basedir = \"lfw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "688c7333-20ff-4614-920d-8d53485498ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T12:10:00.730730Z",
     "iopub.status.busy": "2021-04-28T12:10:00.730087Z",
     "iopub.status.idle": "2021-04-28T12:10:00.790850Z",
     "shell.execute_reply": "2021-04-28T12:10:00.790310Z",
     "shell.execute_reply.started": "2021-04-28T12:10:00.730654Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-jr1ur_cf/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d3a932ca0092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilter_single_face_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoto_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-3f068e45cc2d>\u001b[0m in \u001b[0;36mfilter_single_face_dnn\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcrop_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-jr1ur_cf/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "filter_single_face_dnn(os.path.join(person_path, photo_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5535bafe-3980-49a6-85d2-5061f9e7223a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T12:09:52.218350Z",
     "iopub.status.busy": "2021-04-28T12:09:52.218077Z",
     "iopub.status.idle": "2021-04-28T12:09:52.223571Z",
     "shell.execute_reply": "2021-04-28T12:09:52.222753Z",
     "shell.execute_reply.started": "2021-04-28T12:09:52.218317Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lfw/Igor_Ivanov/Igor_Ivanov_0012.jpg'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(person_path, photo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "12b09b0c-d8ea-40af-b4f9-05d5f25805fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-28T12:09:41.984733Z",
     "iopub.status.busy": "2021-04-28T12:09:41.984382Z",
     "iopub.status.idle": "2021-04-28T12:09:44.186826Z",
     "shell.execute_reply": "2021-04-28T12:09:44.186278Z",
     "shell.execute_reply.started": "2021-04-28T12:09:41.984694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Igor_Ivanov:   1%|          | 1/158 [00:00<00:22,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lfw/George_HW_Bush/George_HW_Bush_0002.jpg due to 2 faces recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Igor_Ivanov:   1%|▏         | 2/158 [00:00<00:23,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lfw/Gloria_Macapagal_Arroyo/Gloria_Macapagal_Arroyo_0003.jpg due to 2 faces recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Igor_Ivanov:   2%|▏         | 3/158 [00:00<00:41,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lfw/Gloria_Macapagal_Arroyo/Gloria_Macapagal_Arroyo_0022.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gloria_Macapagal_Arroyo/Gloria_Macapagal_Arroyo_0028.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gloria_Macapagal_Arroyo/Gloria_Macapagal_Arroyo_0029.jpg due to 2 faces recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Igor_Ivanov:   3%|▎         | 5/158 [00:01<00:30,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lfw/Tiger_Woods/Tiger_Woods_0010.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gordon_Brown/Gordon_Brown_0006.jpg due to 3 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0020.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0021.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0023.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0029.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0037.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0046.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0049.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0057.jpg due to 2 faces recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Igor_Ivanov:   4%|▍         | 6/158 [00:02<01:12,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0073.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0076.jpg due to 2 faces recognized\n",
      "Skipping lfw/Gerhard_Schroeder/Gerhard_Schroeder_0077.jpg due to 2 faces recognized\n",
      "Skipping lfw/Igor_Ivanov/Igor_Ivanov_0001.jpg due to 2 faces recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Igor_Ivanov:   4%|▍         | 6/158 [00:02<00:55,  2.75it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-jr1ur_cf/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-0bf38e0d80c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mphoto_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperson_photo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_photo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mphotos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_single_face_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoto_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphotos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             print(\n",
      "\u001b[0;32m<ipython-input-76-3f068e45cc2d>\u001b[0m in \u001b[0;36mfilter_single_face_dnn\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcrop_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-jr1ur_cf/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "X_train = []\n",
    "y_train = []\n",
    "for person in tqdm(os.listdir(basedir), desc=person):\n",
    "    person_path = os.path.join(basedir, person)\n",
    "    person_photo = os.listdir(person_path)\n",
    "    if len(person_photo) < 10:\n",
    "        print(\"Skipping {} due to {} images ...\",person_photo,len(person_photo))\n",
    "        continue\n",
    "    for photo_path in person_photo[0 : int(len(person_photo) * train_size)]:\n",
    "        photos = filter_single_face_dnn(os.path.join(person_path, photo_path))\n",
    "        if len(photos) > 1:\n",
    "            print(\n",
    "                \"Skipping {} due to {} faces recognized\".format(\n",
    "                    os.path.join(person_path, photo_path), len(photos)\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "        X_train.append(photos[0])\n",
    "        y_train.append(person)\n",
    "#     for photo in person_photo[int(len(person_photo)*train_size):]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
